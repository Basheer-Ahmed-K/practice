# DataFrame Operations and String Functions in PySpark

## DataFrame Operations
- Total number of rows: Obtains the total number of rows in the DataFrame.
- Select: Retrieves specified columns from the DataFrame.
- Filter & Where: Filters data based on specified conditions.
- Like: Filters data based on pattern matching.
- Describe: Generates summary statistics for numerical columns.
- Columns: Displays the names of columns in the DataFrame.
- When & Otherwise: Implements conditional logic to create new columns.
- Alias: Renames columns in the DataFrame.
- OrderBy & Sort: Sorts the DataFrame based on column values.
- GroupBy & GroupBy Agg: Groups data and performs aggregation functions.

## String Functions
- Upper: Converts a string column to uppercase.
- Trim: Removes leading and trailing whitespace from a string column.
- LTrim: Removes leading whitespace from a string column.
- RTrim: Removes trailing whitespace from a string column.
- Translate: Replaces characters in a string column based on a translation map.
- SubstringIndex: Extracts a substring from a string before a specified delimiter.
- Substring: Retrieves a substring from a string column.
- Split: Splits a string column into an array of substrings based on a delimiter.
- Repeat: Repeats a string column a specified number of times.
- RPad: Right-pads a string column to a specified width with a given character.
- LPad: Left-pads a string column to a specified width with a given character.
- RegexReplace: Replaces substrings in a string column based on a regular expression.
- Lower: Converts a string column to lowercase.
- RegexExtract: Extracts a substring from a string column using a regular expression.
- Length: Calculates the length of a string column.
